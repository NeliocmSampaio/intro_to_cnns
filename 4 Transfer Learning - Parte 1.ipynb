{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning usando lasagne - parte 1\n",
    "\n",
    "Nesse tutorial, vamos utilizar CNNs treinadas na base ImageNet para outros problemas de classificação de imagens, usando transfer learning.\n",
    "\n",
    "O objetivo é treinar um modelo para discriminar um subconjunto de 5 classes da base de dados Caltech 101 (http://www.vision.caltech.edu/Image_Datasets/Caltech101/). A base para esse exercício possui 325 imagens de tamanho 224x224x3. \n",
    "\n",
    "Na parte 1 desse tutorial, vamos utilizar o método \"DeCAF\" descrito em [1]: \n",
    " 1. Vamos utilizar uma rede treinada na base ImageNet: https://github.com/Lasagne/Recipes/tree/master/modelzoo\n",
    " 2. Usaremos essa rede para \"extrair características\" da base Caltech, aplicando forward-propagation e obtendo as ativações em uma das últimas camadas da rede\n",
    " 3. Vamos treinar modelos lineares utilizando essa representação\n",
    "\n",
    "\n",
    "[1] Jeff Donahue et al., “DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition,” arXiv:1310.1531 [Cs], October 5, 2013, http://arxiv.org/abs/1310.1531."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib  # Para baixar o modelo\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import cPickle # Para carregar o modelo do disco\n",
    "import matplotlib.pyplot as plt # Para visualizações\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Começamos carregando a base de dados:\n",
    "\n",
    "if not os.path.exists('caltech_5classes.npz'):\n",
    "    print 'Baixando base de dados'\n",
    "    urllib.urlretrieve('http://www.inf.ufpr.br/lghafemann/caltech_5classes.npz', 'caltech_5classes.npz')\n",
    "    print 'Concluído'\n",
    "\n",
    "data = np.load('caltech_5classes.npz')\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']\n",
    "classes = data['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classes:\n",
    "print classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mostrando alguns exemplos da base de dados\n",
    "\n",
    "f, ax = plt.subplots(3,3, figsize=(8,8))\n",
    "random_idx = np.random.choice(len(x_train), 9)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        idx = random_idx[i*3+j]\n",
    "        ax[i][j].imshow(x_train[idx])\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i][j].set_title(classes[y_train[idx]])\n",
    "f.suptitle('Exemplos da base de dados', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados de treinamento portanto possui 5 classes('caranguejo' 'lagostim' 'crocodilo' 'dalmata' 'golfinho'), e um total de  260 imagens de tamanho 224x224, com 3 canais (imagem colorida - RGB).\n",
    "\n",
    "Notamos que essa base de dados é muito mais complexa do que trabalhamos anteriormente. Nesse exercício, iremos utilizar uma rede convolucional treinada na base Imagenet para extraírmos características nessa base.\n",
    "\n",
    "Vamos primeiro separar a base de dados em treinamento e validação. Podemos fazer isso utilizando a seguinte função do pacote 'scikit-learn':\n",
    "\n",
    "```\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=fracao_de_teste)\n",
    "```\n",
    "\n",
    "Essa função divide uma base de dados em treinamento e teste (ou treinamento e validação, no nosso caso). O parâmetro \"test_size\" representa a fração de exemplos a ser usado para teste (deve ser entre 0 e 1). Vamos criar uma base de validação com 20% dos exemplos (e portanto, 80% para treinamento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Base de treino: ', x_train.shape\n",
    "print 'Base de validacao: ', x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Regressão logística diretamente nos pixels\n",
    "\n",
    "Para termos uma referência para comparação, vamos treinar um modelo de regressão logística utilizando diretamente os pixels como entrada.\n",
    "\n",
    "Para tanto, vamos considerar cada exemplo como um vetor de tamanho 224x224x3 = 150528 dimensões:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape(len(x_train), -1)\n",
    "x_valid_flat = x_valid.reshape(len(x_valid), -1)\n",
    "\n",
    "print x_train_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: aplicação de regressão logística\n",
    "\n",
    "Nesse exercício, vamos utilizar a biblioteca scikit-learn para treinar e verificar um modelo de regressão logística.\n",
    "Essa biblioteca possui implementação de vários algoritmos de aprendizagem de máquina, com uma interface fácil de usar.\n",
    "\n",
    "Para esse exercício, vamos treinar um modelo usando x_train_flat e y_train, e avaliar a performance na base de validação. Para isso, utilize a classe ```sklearn.linear_model.LogisticRegression``` ([manual](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression))\n",
    "\n",
    "Dica: verifique a seção \"Methods\" do manual, em especial os métodos \"fit\" e \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sua solução\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Codigo para treinar o modelo e verificar a performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/transfer_linear.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que a performance é ~ 50%. Para uma base de dados com 5 classes, onde um classificador aleatório está certo 20% das vezes, essa é uma taxa bem baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando um modelo pré-treinado na biblioteca Lasagne\n",
    "\n",
    "Treinar um modelo grande na base ImageNet (que contém milhões de imagens) requer vários dias (ou semanas) mesmo utilizando boas GPUs em paralelo. Felizmente, alguns autores disponibilizam suas redes treinadas online, para facilitar a pesquisa de outras pessoas.\n",
    "\n",
    "Para a biblioteca lasagne, tais modelos podem ser encontrados nesse link:\n",
    "\n",
    "https://github.com/Lasagne/Recipes/tree/master/modelzoo\n",
    "\n",
    "À seguir, vamos utilizar uma dessas redes, conhecida como vgg_cnn_s (publicada em [2]). Para tanto, precisamos baixar tanto a definição do modelo (um arquivo .py que implementa a arquitetura), quanto os pesos (em um arquivo \"pickle\").\n",
    "\n",
    "[2] Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition,” arXiv:1409.1556 [Cs], September 4, 2014, http://arxiv.org/abs/1409.1556."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo a arquitetura do modelo\n",
    "\n",
    "Execute as células abaixo para baixar o modelo vgg_cnn_s.py e carregar o seu conteúdo para esse notebook (se você encontrar um erro, leia as células seguintes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('vgg_cnn_s.py'):\n",
    "    print 'Baixando a definição do modelo'\n",
    "    urllib.urlretrieve('https://raw.githubusercontent.com/Lasagne/Recipes/master/modelzoo/vgg_cnn_s.py', 'vgg_cnn_s.py')\n",
    "    print 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load vgg_cnn_s.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo disponibilizado contém a definição do modelo. Notamos que o modelo possui 8 camadas, contendo camadas convolucionais, max-pooling e camadas fully-connected, que utilizamos ontem, assim como outras camadas (dropout, Local Response Normalization).\n",
    "\n",
    "## Importante:\n",
    "\n",
    "Ao tentar executar o código acima, vamos obter um erro, pois o modelo espera o uso de GPUs, que não estão disponíveis nesses computadores. Para utilizarmos esse modelo, precisamos fazer uma pequena alteração no código acima:\n",
    "\n",
    "## Exercício: \n",
    "\n",
    "Altere na célula acima a linha que importa a camada Conv2DLayer, para utilizar a versão que funciona tanto em CPU quanto GPU. Isto é, altere:\n",
    "\n",
    "```\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "```\n",
    "\n",
    "para\n",
    "\n",
    "```\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "```\n",
    "\n",
    "Em seguida, execute a célula acima. Vamos agora criar esse modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analizar algumas propriedades desse modelo, como quais camadas ele possui, quantos parâmetros, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lista de camadas disponíveis:\n",
    "model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde a camada de entrada é a \"input\", e a camada de saída chama-se \"prob\".\n",
    "\n",
    "Para verificarmos o tamanho da entrada, podemos verificar a propriedade ```model['input'].shape```\n",
    "\n",
    "Para verificarmos a saída de uma determinada camada, podemos usar a seguinte função:\n",
    "\n",
    "```\n",
    "tamanho = lasagne.layers.get_output_shape(camada)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tamanho da entrada e da saída:\n",
    "\n",
    "print 'Tamanho da entrada: ', model['input'].shape\n",
    "print 'Tamanho da camada fc7: ', lasagne.layers.get_output_shape(model['fc7'])\n",
    "print 'Tamanho da camada prob: ', lasagne.layers.get_output_shape(model['prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, a entrada é um conjunto de imagens de tamanho 224x224, com 3 canais. A saída possui 1000 classes (as 1000 classes da base de dados ImageNet), e a penúltima camada possui dimensão 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Número de parâmetros do modelo:\n",
    "\n",
    "print lasagne.layers.count_params(model['prob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo possui mais de 102 milhões de parâmetros(!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando os parâmetros treinados na base Imagenet\n",
    "\n",
    "Acima, nós carregamos a definição do modelo vgg_cnn_s, mas esse modelo foi criado com pesos aleatórios. Vamos agora fazer o download dos pesos (conforme definido no arquivo vgg_cnn_s.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('vgg_cnn_s.pkl'):\n",
    "    print 'Baixando pesos (394MB)'\n",
    "    urllib.urlretrieve('https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl', 'vgg_cnn_s.pkl' )\n",
    "    print 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = cPickle.load(open('vgg_cnn_s.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo baixado possui três informações:\n",
    "\n",
    "* values - a lista de parâmetros treinados\n",
    "* synset words - nome das 1000 classes da base Imagenet\n",
    "* mean image - a imagem média que foi utilizada para treinamento\n",
    "\n",
    "Esse terceiro parâmetro será explicado em mais detalhes abaixo. Por hora, vamos utilizar o primeiro parâmetro para carregar os pesos treinados no nosso modelo, usando a função\n",
    "\n",
    "```\n",
    "lasagne.layers.set_all_param_values(camada_de_saida, parametros)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasagne.layers.set_all_param_values(model['prob'], params['values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "**importante:** Em Transfer Learning, além de utilizar a rede com os mesmos pesos, é importante utilizarmos as mesmas etapas de pré-processamento que foram utilizados na base de dados origem antes do treinamento da rede neural. \n",
    "\n",
    "Em geral, um dos pré-processamentos amplamente utilizados para treinamento de redes neurais é o chamado \"normalização da média\" (mean normalization). Esse processo refere-se a modificar a base de treinamento para que cada dimensão possua média 0 ao longo da base de treinamento. Isso é feito da seguinte forma:\n",
    "\n",
    "```\n",
    "media = X.mean(axis=0)\n",
    "X = X - media\n",
    "```\n",
    "\n",
    "Para novas imagens é importante seguir o mesmo procedimento (subtrair a média de cada dimensão). Para isso, vamos usar a media estimada na base de treinamento, que é dada por ```params['mean image']```. \n",
    "\n",
    "Além disso, precisamos tomar outras duas ações:\n",
    "\n",
    "1. A nossa base de dados possui tamanho (208, 224, 224, 3): Número de exemplos x Altura x Largura x Canais RGB. A entrada da rede é (None, 3, 224, 224). Precisamos portanto modificar a ordem das dimensões. Podemos fazer isso usando a função ```np.transpose```\n",
    "2. A base de dados possui canais RGB (vermelho, verde, azul), e o modelo usa o padrão BGR (azul, verde, vermelho). Podemos mudar esse padrão usando indexação de matrizes no Numpy: A sintaxe X[::-1] inverte a ordem de uma matrix (em determinada dimensão - ex: [1,2,3] passaria a ser [3,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_img = params['mean image']\n",
    "\n",
    "def process_dataset(x):\n",
    "    x = np.transpose(x, (0,3,1,2))  # Modifica dados para: exemplos x canais RGB x altura x largura\n",
    "    x = x[:, ::-1]                  # Modifica canais de RGB para BGR\n",
    "    \n",
    "    x = x - mean_img\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_processed = process_dataset(x_train)\n",
    "x_valid_processed = process_dataset(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício - transfer learning\n",
    "\n",
    "Possuímos agora a base de dados destino (tarefa de classificação das 5 classes) no formato correto para o modelo pré-treinado. \n",
    "\n",
    "Esse exercício consiste em fazer o transfer learning da base ImageNet para a base Caltech-5classes, usando o método DeCAF[[1](http://arxiv.org/abs/1310.1531)]:\n",
    "\n",
    "![](images/oquab_decaf.svg.png)\n",
    "\n",
    "Dado que a rede já está treinada, os passos serão:\n",
    "\n",
    "1. Obter a saída da camada *fc7*, ao fazer forward-propagation da base de treinamento (x_train) e validação (x_valid)\n",
    "2. Criar um modelo de regressão logística usando sklearn. Treinar usando os vetores de características ex\n",
    "3. Avaliar a performance em validação, usando a representação na camada *fc7*\n",
    "\n",
    "\n",
    "Dicas:\n",
    "\n",
    "* Use ```lasagne.layers.get_output``` para obter a saída da rede em uma camada à sua escolha. Lembre de usar o parametro \"deterministic=True\"\n",
    "* Obter as representações (forward-propagation) utiliza bastante memória, então é recomendável fazê-lo em mini-batches (isto é, obter a representação de alguns exemplos a cada vez). Para isso, após compilar uma função do theano para obter as representações, use a função ```get_output_batch``` definida abaixo para aplicá-la à toda a base de treino/validação: ```x_train_processed, x_valid_processed```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Roda uma função em batches e concatena o resultado:\n",
    "def get_output_batch(function, x, batch_size=32):\n",
    "    output = []\n",
    "    for batch_start in xrange(0, len(x), batch_size):\n",
    "        output.append(function(x[batch_start:batch_start+batch_size]))\n",
    "    return np.vstack(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sua solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/transfer_decaf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Obtemos um resultado superior à 90% - uma boa melhora comparado ao modelo de regressão logística usando pixels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando as entradas classificadas incorretamente\n",
    "\n",
    "## Exercício: Obtendo predições do modelo\n",
    "\n",
    "Obtenha as predições do modelo treinado acima, para a base de dados de validação. \n",
    "\n",
    "Dica: utilize a função ```<classificador>.predict``` [link](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sua solução\n",
    "\n",
    "valid_preds = # codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/transfer_preds.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Função para exibir uma imagem e a predição do modelo\n",
    "\n",
    "def plot_img(X, y, ypred, ax=None):\n",
    "    mean_img = params['mean image']\n",
    "    if (ax == None):\n",
    "        f, ax = plt.subplots()\n",
    "        \n",
    "    #Desfazendo o pré-processamento das imagens:\n",
    "    img = X+mean_img\n",
    "    img = img [::-1]\n",
    "    img = np.transpose(img,[1,2,0])\n",
    "    ax.imshow(img.astype(np.uint8))\n",
    "    ax.set_title('Predicao do modelo: %s; correto: %s' % (classes[ypred], classes[y]))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_idx = np.flatnonzero(valid_preds != y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(error_idx), figsize=(12,8))\n",
    "for i in range(len(error_idx)):\n",
    "    idx = error_idx[i]\n",
    "    plot_img(x_valid[idx], y_valid[idx], valid_preds[idx], ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: Performance na base de teste\n",
    "\n",
    "Avalie a performance na base de teste, seguindo os mesmos passos que usamos para validação:\n",
    "\n",
    "1. Execute o pré-processamento nas imagens de teste\n",
    "2. Use a rede pré-treinada para obter a representação na camada fc7\n",
    "3. Use o modelo linear treinado para obter o score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sua solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/transfer_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante: antes de rodar a parte 2, feche esse notebook (File ->close and halt) para liberar a memória utilizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios extras:\n",
    "\n",
    "* No exercício acima, usamos apenas uma divisão da base entre treinamento e validação. No caso de bases pequenas, uma estratégia mais robusta para estimar o erro chama-se k-fold cross-validation. Use Scikit-Learn para implementar esse tipo de validação ([manual](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation))\n",
    "\n",
    "* Faça o treinamento utilizando a representação obtida em outras camadas (e.g. fc6)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
